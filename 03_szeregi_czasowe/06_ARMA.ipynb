{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUT-bSL3x8xu"
   },
   "source": [
    "# Modelowanie ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsnwHq1Ex8x1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-1L_QUpysSm"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_time_series_stationary(y, rolling_len=12):\n",
    "    \n",
    "    y = pd.Series(y)\n",
    "    df_test = adfuller(y)\n",
    "    \n",
    "    if df_test[1] < 0.05:\n",
    "        print('Szereg jest stacjonarny')\n",
    "    \n",
    "    else:\n",
    "        print('Szereg jest niestacjonarny')\n",
    "    \n",
    "    print(\"{0:^32s}\".format(\"Dickey-Fuller Test\"))\n",
    "    print(\"-\"*32+\"\\n\")\n",
    "    \n",
    "    print(\"{0:<20s}: {1:>10.4f}\".format('Test Statistic', df_test[0]))\n",
    "    print(\"{0:<20s}: {1:>10.4f}\".format('p-value', df_test[1]))\n",
    "    print(\"-\"*32+\"\\n\")\n",
    "    \n",
    "    rolling_mean = y.rolling(rolling_len).mean()\n",
    "    rolling_var = y.rolling(rolling_len).var()\n",
    "\n",
    "    plt.plot(y)\n",
    "    plt.plot(rolling_mean, label=\"Rolling mean\")\n",
    "    plt.plot(rolling_var, label=\"Rolling var\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"{0:^32s}\".format(\"Autocorrelation plot\"))\n",
    "    print(\"-\"*32+\"\\n\")\n",
    "    \n",
    "    pd.plotting.autocorrelation_plot(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtxaArXbx8x3"
   },
   "source": [
    "## Zadanie 1\n",
    "\n",
    "Dokonaj analizy szeregu czasowego `USGDP`. Dopasuj odpowiedni model i dokonaj predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mq2toyTwbAnO"
   },
   "outputs": [],
   "source": [
    "usgdp = pd.read_csv('../data/USGDP.csv', parse_dates=['DATE'], index_col='DATE')\n",
    "usgdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JiujaFebCP-"
   },
   "outputs": [],
   "source": [
    "check_time_series_stationary(usgdp.GDPC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI_nGpKux59T"
   },
   "outputs": [],
   "source": [
    "log_usgdp = np.log(usgdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWVIwBPEyD5R"
   },
   "outputs": [],
   "source": [
    "check_time_series_stationary(log_usgdp.GDPC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JorPxLKQyL83"
   },
   "outputs": [],
   "source": [
    "log_usgdp_diff = log_usgdp.diff(1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iVo5d8QyhwS"
   },
   "outputs": [],
   "source": [
    "check_time_series_stationary(log_usgdp_diff.GDPC1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKXvxxasx8yF"
   },
   "source": [
    "### Dopasowanie modelu\n",
    "\n",
    "Diagnostyka modelu sprowadza się m.in do:\n",
    "- analizy reszt - jeśli dopadowany model poprawnie wyjaśnia dynamikę czasową analizowanego zjawiska, w szeregu reszt nie powinno być widać żadnych regularnych zachowań (trendu, sezonowości), ani istotnej korelacji czasowej (dla żadnego z opóźnień), stąd:\n",
    "    - w praktyce możemy posługiwać się regułą, że reszty dopasowanego modelu powinny zachowywać się w przybliżeniu jak biały szum,\n",
    "    - często weryfikujemy również dodatkowo, czy rozkład reszt można uznawać za rozkład normalny\n",
    "    \n",
    "W praktyce sprawdzamy najczęściej \n",
    "- wykres reszt - na wykresie nie powinno być widocznych regularnych wzorów ani niejednorodności wariancji, \n",
    "- test Durbina-Watsona - niezależność błędów obserwacji, dobrze dopasowany model zakłada, że otrzymywane reszty są niezależne od siebie, innymi słowy, rozkład ich jest losowy, przypadkowy, bez stale występującego wzorca. \n",
    "- ACF/PACF dla reszt - na wykresach nie powinno być widocznych istotnych korelacji (tzw. *graficzny test białoszumowości*),\n",
    "- weryfikacja normalności rozkładu reszt - wykorzystujemy narzędzia graficzne (np. Q-Q plot lub histogram) oraz formalne testy statystyczne normalności (np. test Shapiro-Wilka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sRBRNxA7bev"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp4TVtOhx8yG"
   },
   "source": [
    "### Test Durbina-Watsona\n",
    "\n",
    "Statystyka DW mieści się w przedziale od 0 do 4:\n",
    "- w przypadku DW > 2, zakłada się występowanie autokorelacji ujemnej, \n",
    "- w przypadku DW < 2 autokorelacji dodatniej,\n",
    "- wartości zbliżone do 2 oznaczają brak występowania autokorelacji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrePe-pI7cc_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkqpHViox8yG"
   },
   "source": [
    "### Wykres reszt za pomocą ACF i PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OS4ly8Au7dw_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7q-5LM5Zx8yH"
   },
   "source": [
    "### Weryfikacja normalności rozkładu reszt\n",
    "\n",
    "1. Test Shapiro-Wilka\n",
    "\n",
    "    H0: Rozkład badanej cechy jest rozkładem normalnym.\n",
    "\n",
    "    H1: Rozkład badanej cechy nie jest rozkładem normalnym.\n",
    "    \n",
    "\n",
    "2. Wykres $Q-Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5aX5dPV7gfz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYRqgGUyx8yE"
   },
   "source": [
    "### Analiza istotności współczynników w modelu\n",
    "\n",
    "Jakość dopasowania modelu można niekiedy poprawić eliminując te współczynniki, które są statystycznie nieistotne, to znaczy nie odgrywają istotnej roli w wyjaśnianiu dynamiki czasowej modelowanego zjawiska.\n",
    "\n",
    "Formalnie, sprawdzamy hipotezę zerową postaci \n",
    "$$H_0: \\phi_i = 0,$$\n",
    "kontra hipotezie alternatywnej \n",
    "$$H_1: \\phi_i \\neq 0$$.\n",
    "\n",
    "Odrzucenie $H_0$ przemawia za pozostawieniem współczynnika $\\phi_i$ w modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWoSB7n27iKD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvDKYVnox8yJ"
   },
   "source": [
    "### Dopasowanie (Predykcja) na podstawie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgMugt9D5Rno"
   },
   "outputs": [],
   "source": [
    "usgdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w3D0m9Px8yK"
   },
   "source": [
    "## Zadanie 2\n",
    "Dla danych\n",
    "\n",
    "1. `southern`\n",
    "\n",
    "2. `daily-total-female-births`\n",
    "\n",
    "dopasuj odpowiedni model $\\text{AR}(p)$ lub $\\text{MA}(q)$ lub $\\text{ARMA}(p, q)$ (rząd $p$ i $q$ wyznacz na podstawie wykresów ACF i PACF). Sprawdź dopasowanie modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq3rF64pQ8jS"
   },
   "outputs": [],
   "source": [
    "daily_biths = pd.read_csv('../data/daily-total-female-births.csv', parse_dates=['Date'], index_col='Date')\n",
    "daily_biths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZX_Q5fJQ-ua"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Axa8eWvvx8yN"
   },
   "source": [
    "# Kryteria informacyjne oceniają jakość dopasowania modelu\n",
    "\n",
    "Kryteria informacyjne oceniają jakość dopasowania modelu na podstawie danych historycznych, kontrolując jednocześnie stopień złożoności modelu. \n",
    "\n",
    "Zwiększając liczbę parametrów modelu (zwiększając złożoność modelu), możemy zazwyczaj otrzymać lepsze dopasowanie modelu do danych. Zbyt dobre dopasowanie modelu może jednak powodować problemy, a w szczególności może prowadzić do złych prognoz. Z tego powodu w postaci kryteriów wyboru modelu występuje składnik kary za wymiar modelu, w ogólności:\n",
    "\n",
    "$$C(\\text{model}) = -2 \\ln(L) + \\text{kara(liczba współczynników modelu)},$$\n",
    "gdzie $L$ oznacza funkcję wiarogodności.\n",
    "\n",
    "**AIC (Akaike Information Criterium)**\n",
    "$$AIC(p, q) = -2 \\ln(L) + 2\\cdot(p+q+1)$$\n",
    "\n",
    "**BIC (Bayesian Information Criterium)**\n",
    "$$BIC(p, q) = -2 \\ln(L) + (p+q+1)\\cdot\\ln n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ElPvU2Lx8yN"
   },
   "source": [
    "### Kryteria oceniające dokładność prognoz \n",
    "\n",
    "- MSE - Mean Squared Error\n",
    "- MAE - Median Absolute Error\n",
    "\n",
    "Należy jednak pamiętać, że w odróżnieniu od kryteriów infromacyjnych, kryteria oparte na błędach predykcji nie mają wbudowanego mechanizmu, który \"karałby\" za złożoność modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcwkl5pox8yN"
   },
   "source": [
    "## Zadanie 3\n",
    "\n",
    "Napisz funkcję, która dla dowolnego szeregu czasowego i modelu `ARMA` sprawdzi jego dopasowanie oraz jakość predykcji na podstawie MSE i MAE.\n",
    "Zawrzyj informację o wartości oszacowanych współczynników modelu, wartości AIC i BIC, wartości statystyki Durbina-Watsona oraz ocenę normalności reszt.\n",
    "\n",
    "Następnie sprawdź dopasowanie dla kilku wybranych modeli ARMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAQHjtozx8yO"
   },
   "outputs": [],
   "source": [
    "def mse(y, yhat):\n",
    "    return np.mean((y - yhat)**2)\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return np.median(np.abs(y - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feJJn-F_x8yO"
   },
   "outputs": [],
   "source": [
    "def fit_ARMA(ts, p, q, pred_start, pred_end):\n",
    "    \n",
    "    arma = ARIMA(ts, order=(p, 0, q)).fit()\n",
    "    \n",
    "    print('AR params %s' % arma.arparams)\n",
    "    print('MA params %s' % arma.maparams)\n",
    "    \n",
    "    print('AIC: %.2f, \\nBIC: %.2f' % (arma.aic, arma.bic))\n",
    "    \n",
    "    dw_test = sm.stats.durbin_watson(arma.resid)\n",
    "    print(\"Statystyka Durbina-Watsona {}\".format(dw_test))\n",
    "    \n",
    "    normal_test = stats.shapiro(arma.resid)\n",
    "    print(\"Pvalue testu Shapiro-Wilka: {}\".format(normal_test[1]))\n",
    "    \n",
    "    pred = arma.predict(start=pred_start, end=pred_end, dynamic=True)\n",
    "        \n",
    "    mse_val = mse(ts.values, pred.values)\n",
    "    mae_val = mae(ts.values, pred.values)\n",
    "    print('MSE: {}'.format(mse_val))\n",
    "    print('MAE: {}'.format(mae_val))\n",
    "    \n",
    "    plt.plot(ts)\n",
    "    plt.plot(pred, 'g--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oew4dM0mRJqT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsdxIKEFx8yP"
   },
   "source": [
    "# Optymalna wartość $p$ na podstawie kryterium oceniającego dobroć dopasowania modelu (AIC lub BIC)\n",
    "\n",
    "## Zadanie 4\n",
    "Napisz funkcję, która dla danego szeregu czasowego wyznaczy najlepszy rząd $p$ modelu $\\text{AR}(p)$ na podstawie kryterium AIC i BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UE53VJJDx8yP"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def find_the_best_parametr_ar(ts, max_p=10):\n",
    "    \n",
    "    aic = np.zeros(max_p)\n",
    "    bic = np.zeros(max_p)\n",
    "    \n",
    "    for i in range(1, max_p + 1):\n",
    "        \n",
    "        ar = ARIMA(ts, (i, 0, 0)).fit()\n",
    "        aic[i-1] = ar.aic\n",
    "        bic[i-1] = ar.bic\n",
    "        \n",
    "    plt.plot(range(1, max_p + 1), aic, 'r.-', label=\"AIC\")\n",
    "    plt.plot(range(1, max_p + 1), bic, 'g.-', label=\"BIC\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"Najlepszy rząd p: {} dla kryterium AIC (AIC={})\".format(np.argmin(aic) + 1, np.min(aic)))\n",
    "    print(\"Najlepszy rząd p: {} dla kryterium BIC (BIC={})\".format(np.argmin(bic) + 1, np.min(bic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVabNsFVx8yQ"
   },
   "source": [
    "## Zadanie 5\n",
    "\n",
    "Napisz funkcję, która dla danego szeregu czasowego wyznaczy najlepszy rząd $p$ i $q$ modelu $\\text{ARMA}(p)$ na podstawie kryterium AIC i BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNmAXEdCx8yQ"
   },
   "outputs": [],
   "source": [
    "def find_the_best_arma(ts, max_p=10, max_q=10):\n",
    "    \n",
    "    aic = np.zeros((max_p, max_q))\n",
    "    bic = np.zeros((max_p, max_q))\n",
    "    \n",
    "    for i in range(max_p):\n",
    "        for j in range(max_q):\n",
    "            \n",
    "            arma = ARIMA(ts, order=(i + 1, 0, j + 1)).fit()\n",
    "            aic[i, j] = arma.aic\n",
    "            bic[i, j] = arma.bic\n",
    "            print('ARMA(%d, %d): AIC=%f, BIC=%f' % (i+1, j+1, arma.aic, arma.bic))\n",
    "            \n",
    "    print(\"-\" * 30)\n",
    "    min_aic = np.min(aic)\n",
    "    min_arg_aic = np.argwhere(aic == min_aic)[0]\n",
    "    print(\"MINIMUM AIC=%f dla p=%d, q=%d\" % (min_aic, min_arg_aic[0] + 1, min_arg_aic[1] + 1))\n",
    "    \n",
    "    min_bic = np.min(bic)\n",
    "    min_arg_bic = np.argwhere(bic == min_bic)[0]\n",
    "    print(\"MINIMUM BIC=%f dla p=%d, q=%d\" % (min_bic, min_arg_bic[0] + 1, min_arg_bic[1] + 1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7ElPvU2Lx8yN"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
